# THANKFULLY -- before i got too far, I recalled & found this from the forum:
#    
# Fixing Celery/Redis AttributeError: 
#   'Float' object has no attribute 'items'
# @LeoThalman                                               10 days ago
#
# if you get an Attribute error in celery when adding a task to the
# queue with delay,  then run following command to rollback redis to
# an install that works:
#
#       pip install redis==2.10.6
#
#
#
# THEN DID THIS:
#
# (cs407_inclass_11-15-18_TaskQue-7oW8s1VC)
# ec2-user@ip-172-31-27-206: ~/cs407_inclass_11-15-18_TaskQue:
# $ pip install redis==2.10.6
# Collecting redis==2.10.6
#  Downloading https://files.pythonhosted.org/packages/3b/f6/7a76333cf0b9251ecf49efff635015171843d9b977e4ffcf59f9c4428052/redis-2.10.6-py2.py3-none-any.whl (64kB)
#    100% |████████████████████████████████| 71kB 3.2MB/s
#Installing collected packages: redis
#  Found existing installation: redis 3.0.1
#    Uninstalling redis-3.0.1:
#      Successfully uninstalled redis-3.0.1
#Successfully installed redis-2.10.6
#
#
#(cs407_inclass_11-15-18_TaskQue-7oW8s1VC)
#ec2-user@ip-172-31-27-206: ~/cs407_inclass_11-15-18_TaskQue:
#$ celery -A tasks worker --loglevel=info
#
# -------------- celery@ip-172-31-27-206 v4.2.1 (windowlicker)
#---- **** -----
#--- * ***  * -- Linux-4.14.70-67.55.amzn1.x86_64-x86_64-with-glibc2.3.4 2018-11-26 01:34:16
#-- * - **** ---
#- ** ---------- [config]
#- ** ---------- .> app:         tasks:0x7f89c3209748
#- ** ---------- .> transport:   redis://localhost:6379//
#- ** ---------- .> results:     disabled://
#- *** --- * --- .> concurrency: 1 (prefork)
#-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
#--- ***** -----
# -------------- [queues]
#                .> celery           exchange=celery(direct) key=celery
#
#
#[tasks]
#  . tasks.add
#
#[2018-11-26 01:34:16,852: INFO/MainProcess] Connected to redis://localhost:6379//
#[2018-11-26 01:34:16,859: INFO/MainProcess] mingle: searching for neighbors
#[2018-11-26 01:34:17,876: INFO/MainProcess] mingle: all alone
#[2018-11-26 01:34:17,882: INFO/MainProcess] celery@ip-172-31-27-206 ready.
#
#
#
# AND GOT THIS IN THE PYTHON SHELL:
# 
#   >>> from tasks import add
#   >>> add(4,5)
#   9
#   >>> add.delay(4,5)
#   <AsyncResult: 0b9f55cc-e0c3-402a-964f-5bae202c6fdf>
#
# AND THIS IN THE SHELL RUNNING CELERY:
#
# [2018-11-26 01:36:48,923: INFO/MainProcess] Received task: tasks.add[0b9f55cc-e0c3-402a-964f-5bae202c6fdf]
# [2018-11-26 01:36:48,925: INFO/ForkPoolWorker-1] Task tasks.add[0b9f55cc-e0c3-402a-964f-5bae202c6fdf] succeeded in 0.0004292083904147148s: 9
#
#
# woo-fucking-hoo!  (: 
#
# 
#
# THEN ADDED THE 'backend' PER THE CELERY 1st STEPS TUTORIAL:
# 
# from celery import Celery
#
## this is from assignment instructions --
##       so this is right way to connect to redis:
##         ADDED the backend per the Celery 1st Steps:
#app = Celery('tasks', backend='redis://localhost', broker='redis://localhost')
#
#@app.task
#def add(x, y):
#        return x + y
#
#
# AND STOPPED/RESTARTED THE CELERY WORKER:
#
# ec2-user@ip-172-31-27-206: ~/cs407_inclass_11-15-18_TaskQue:
# $ celery -A tasks worker --loglevel=info
# 
# -------------- celery@ip-172-31-27-206 v4.2.1 (windowlicker)
#---- **** -----
#--- * ***  * -- Linux-4.14.70-67.55.amzn1.x86_64-x86_64-with-glibc2.3.4 2018-11-26 1:41:14
#-- * - **** ---
#- ** ---------- [config]
#- ** ---------- .> app:         tasks:0x7f19e4bb5748
#- ** ---------- .> transport:   redis://localhost:6379//
#- ** ---------- .> results:     redis://localhost/
#- *** --- * --- .> concurrency: 1 (prefork)
#-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
#--- ***** -----
# -------------- [queues]
#                .> celery           exchange=celery(direct) key=celery
#
#
#[tasks]
#  . tasks.add
#
#[2018-11-26 01:41:14,428: INFO/MainProcess] Connected to redis://localhost:6379//
#[2018-11-26 01:41:14,435: INFO/MainProcess] mingle: searching for neighbors
#[2018-11-26 01:41:15,452: INFO/MainProcess] mingle: all alone
#[2018-11-26 01:41:15,458: INFO/MainProcess] celery@ip-172-31-27-206 ready.
#
#
# AND DID/GOT THIS IN THE PYTHON SHELL: 
#   (note i had to exit/re-enter python shell -- before that got error)
#
#   >>> from tasks import add
#   >>> add(4,5)
#   9
#   >>> add.delay(3,6)
#   <AsyncResult: 27d94a6c-ec49-4d32-8124-a48a679f2ef5>
#   >>> result = add.delay(4,5)
#   >>> result.ready()
#   True                         <-- note i got 'true' like right away!
#   >>> result = add.delay(9,9)
#   >>> result.ready()
#   True                         <-- note i got 'true' like right away!
#
#
# AND ALL THIS SHOWED UP ON THE CELERY WORKER SHELL:
# 
# [2018-11-26 01:45:39,240: INFO/MainProcess] Received task: tasks.add[27d94a6c-ec49-4d32-8124-a48a679f2ef5]
# [2018-11-26 01:45:39,247: INFO/ForkPoolWorker-1] Task tasks.add[27d94a6c-ec49-4d32-8124-a48a679f2ef5] succeeded in 0.004556800238788128s: 9
# [2018-11-26 01:46:04,538: INFO/MainProcess] Received task: tasks.add[01765b3e-3b19-4790-9c2b-c59527187cac]
# [2018-11-26 01:46:04,540: INFO/ForkPoolWorker-1] Task tasks.add[01765b3e-3b19-4790-9c2b-c59527187cac] succeeded in 0.00039362069219350815s: 9
# [2018-11-26 01:49:58,635: INFO/MainProcess] Received task: tasks.add[800f08f9-982f-47dd-86a7-d7f6407cac7a]
# [2018-11-26 01:49:58,637: INFO/ForkPoolWorker-1] Task tasks.add[800f08f9-982f-47dd-86a7-d7f6407cac7a] succeeded in 0.0004060901701450348s: 9
# [2018-11-26 01:50:30,006: INFO/MainProcess] Received task: tasks.add[a8293dad-47f4-48be-a079-6e823bacf029]
# [2018-11-26 01:50:30,008: INFO/ForkPoolWorker-1] Task tasks.add[a8293dad-47f4-48be-a079-6e823bacf029] succeeded in 0.0009216554462909698s: 9
# [2018-11-26 01:51:57,496: INFO/MainProcess] Received task: tasks.add[e1938ab4-191f-4807-be1a-2002ccc0d559]
# [2018-11-26 01:51:57,497: INFO/ForkPoolWorker-1] Task tasks.add[e1938ab4-191f-4807-be1a-2002ccc0d559] succeeded in 0.00039995182305574417s: 18
# [2018-11-26 01:58:02,687: INFO/MainProcess] Received task: tasks.add[d7cf7214-b9dd-4f1b-9adc-3cf6f2d43390]
# [2018-11-26 01:58:02,688: INFO/ForkPoolWorker-1] Task tasks.add[d7cf7214-b9dd-4f1b-9adc-3cf6f2d43390] succeeded in 0.0003975173458456993s: 7
# [2018-11-26 02:05:24,334: INFO/MainProcess] Received task: tasks.add[d7efc4a5-3abb-493c-a40c-dd7aeb48533b]
# [2018-11-26 02:05:24,336: INFO/ForkPoolWorker-1] Task tasks.add[d7efc4a5-3abb-493c-a40c-dd7aeb48533b] succeeded in 0.00042986683547496796s: 27
#
#
# BACK TO PYTHON:
#
#   >>> result.get(timeout=3)
#   18
#
#
# so it's working -- but I'm not seeing any noticeable delay... (: 
# 
#   >>> result.traceback
#   >>> sum = add.delay(4,3)
#   >>> result.ready()
#   True
#   >>> sum = add.delay(17,10)
#   >>> sum.ready()
#   True
#
#
# AND BEFORE THERE WAS THIS:
# $ pipenv install celery
#Installing celery...
#Collecting celery
#  Using cached https://files.pythonhosted.org/packages/e8/58/2a0b1067ab2c12131b5c089dfc579467c76402475c5231095e36a43b749c/celery-4.2.1-py2.py3-none-any.whl
#Collecting billiard<3.6.0,>=3.5.0.2 (from celery)
#Collecting kombu<5.0,>=4.2.0 (from celery)
#  Using cached https://files.pythonhosted.org/packages/97/61/65838c7da048e56d549e358ac19c0979c892e17dc6186610c49531d35b70/kombu-4.2.1-py2.py3-none-any.whl
#Collecting pytz>dev (from celery)
#  Using cached https://files.pythonhosted.org/packages/f8/0e/2365ddc010afb3d79147f1dd544e5ee24bf4ece58ab99b16fbb465ce6dc0/pytz-2018.7-py2.py3-none-any.whl
#Collecting amqp<3.0,>=2.1.4 (from kombu<5.0,>=4.2.0->celery)
#  Using cached https://files.pythonhosted.org/packages/7f/cf/12d4611fc67babd4ae250c9e8249c5650ae1933395488e9e7e3562b4ff24/amqp-2.3.2-py2.py3-none-any.whl
#Collecting vine>=1.1.3 (from amqp<3.0,>=2.1.4->kombu<5.0,>=4.2.0->celery)
#  Using cached https://files.pythonhosted.org/packages/10/50/5b1ebe42843c19f35edb15022ecae339fbec6db5b241a7a13c924dabf2a3/vine-1.1.4-py2.py3-none-any.whl
#Installing collected packages: billiard, vine, amqp, kombu, pytz, celery
#Successfully installed amqp-2.3.2 billiard-3.5.0.4 celery-4.2.1 kombu-4.2.1 pytz-2018.7 vine-1.1.4
#
#Adding celery to Pipfile's [packages]...
#Pipfile.lock (3531c3) out of date, updating to (dd8818)...
#Locking [dev-packages] dependencies...
#Locking [packages] dependencies...
#packages/pipenv/utils.py", line 402, in resolve_deps
#    req_dir=req_dir
#  File "/home/ec2-user/.local/lib/python2.7/site-packages/pipenv/utils.py", line 250, in actually_resolve_deps
#    req = Requirement.from_line(dep)
#  File "/home/ec2-user/.local/lib/python2.7/site-packages/pipenv/vendor/requirementslib/models/requirements.py", line 704, in from_line
#    line, extras = _strip_extras(line)
#TypeError: 'module' object is not callable
#
#/home/ec2-user/.local/lib/python2.7/site-packages/pipenv/_compat.py:113: ResourceWarning: Implicitly cleaning up <TemporaryDirectory #'/tmp/pipenv-ye2cVX-requirements'>
#  warnings.warn(warn_message, ResourceWarning)
#
#
#(holmant_CS407_hwk03-eSL_iTeL)
#ec2-user@ip-172-31-27-206: ~/holmant_CS407_hwk03:
#$ celery --version
#4.2.1 (windowlicker)
